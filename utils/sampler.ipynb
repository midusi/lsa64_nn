{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sampler.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdys-tVe8EaB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0510f5a-2352-419b-f334-680cb1ccea0b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/') \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ora3xx07_ME_"
      },
      "source": [
        "K FOLDER\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UV3ZzTrd5Bp"
      },
      "source": [
        "import os\n",
        "from random import randint\n",
        "import numpy as np\n",
        "\n",
        "DATASET = 'SimpleSampling32'\n",
        "NUM_FOLDS = 5\n",
        "def get_cat(sample):\n",
        "        return sample.split(\" \")[0].split('_')[0]\n",
        "\n",
        "def get_subject(sample):\n",
        "        return sample.split('_')[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mW9gfB0eRKI"
      },
      "source": [
        "FOLD MAKER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULmByQbemxTR"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "samples_categorized = {}\n",
        "files = os.listdir(\"/content/gdrive/My Drive/Informática/Tesina/Videos/\"+DATASET)\n",
        "for sample in files:\n",
        "  cat = get_cat(sample)\n",
        "  if cat not in list(samples_categorized.keys()):\n",
        "    samples_categorized[cat] = []    \n",
        "  samples_categorized[cat].append(sample)\n",
        "\n",
        "for cat in list(samples_categorized.keys()):\n",
        "  np.random.shuffle(samples_categorized[cat])\n",
        "\n",
        "folds  = {}\n",
        "\n",
        "for k in range(NUM_FOLDS): # para cada fold\n",
        "  folds[k] = []\n",
        "  for key in list(samples_categorized.keys()): #junto 10% de cada clase\n",
        "    for t in range (len(files)//NUM_FOLDS//64): #para \n",
        "      folds[k].append(samples_categorized[key].pop())\n",
        "  np.random.shuffle(folds[k])\n",
        "  with open(os.path.join(\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/\"+DATASET,f'{k}_fold.txt'), 'w') as f:\n",
        "    f.write('\\n'.join(folds[k]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXGoPeIceS1m"
      },
      "source": [
        "TRAIN-VAL SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "374HIlbG5BOI"
      },
      "source": [
        "\n",
        "\n",
        "for i in range(0,5):\n",
        "  l = []\n",
        "  for t in range(NUM_FOLDS):\n",
        "    with open(os.path.join(f\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/{DATASET}\",f'{t}_fold.txt'), 'r') as f:\n",
        "      l.append(f.read().split('\\n'))  \n",
        "  #ELEGIR EL FOLD PARA TESTEO\n",
        "\n",
        "  test_fold = i\n",
        "  print(\"estas tocando aca \"+f\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/{DATASET}:\")\n",
        "  print(os.listdir(f\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/{DATASET}\"))\n",
        "\n",
        "  test = l.pop(test_fold)\n",
        "  train = [item for sublist in l for item in sublist]\n",
        "  print(len(train)+len(test))\n",
        "  train_categorized = {}\n",
        "  for sample in train:\n",
        "    cat = get_cat(sample)\n",
        "    if cat not in list(train_categorized.keys()):\n",
        "      train_categorized[cat] = []    \n",
        "    train_categorized[cat].append(sample)\n",
        "\n",
        "\n",
        "\n",
        "  print(len(train_categorized[str(0)]))\n",
        "  val_list = []\n",
        "  for i in range(64):\n",
        "    class_val = {}\n",
        "    for sub in range(10):\n",
        "      while True:  \n",
        "        idx = np.random.randint(0, len(train_categorized[str(i)]))\n",
        "        train_sample = train_categorized[str(i)][idx]\n",
        "        train_sub = get_subject(train_sample)      \n",
        "        if train_sub not in class_val.keys():\n",
        "          class_val[train_sub] = train_categorized[str(i)].pop(idx)\n",
        "          break\n",
        "    s1 = np.random.randint(0,10)\n",
        "    s2 = np.random.randint(0,10)\n",
        "    while s1 == s2:\n",
        "      s2 = np.random.randint(0,10)\n",
        "    s3 = np.random.randint(0,10)\n",
        "    while s3 == s2 or s3 == s1:\n",
        "      s3 = np.random.randint(0,10)\n",
        "    \n",
        "    train_categorized[str(s1)].append(class_val.pop(str(s1)))\n",
        "    train_categorized[str(s2)].append(class_val.pop(str(s2)))\n",
        "    train_categorized[str(s3)].append(class_val.pop(str(s3)))\n",
        "    val_list.append(list(class_val.values()))\n",
        "    \n",
        "  val = [item for sublist in val_list for item in sublist]\n",
        "  train_list = list(train_categorized.values())\n",
        "  train = [item for sublist in train_list for item in sublist]\n",
        "  print(len(val))\n",
        "  print(len(val)+len(train))\n",
        "  val_categorized = {}\n",
        "  for sample in val:\n",
        "    cat = get_cat(sample)\n",
        "    if cat not in list(val_categorized.keys()):\n",
        "      val_categorized[cat] = []    \n",
        "    val_categorized[cat].append(sample)\n",
        "\n",
        "\n",
        "  print(len(val_categorized[str(0)]))\n",
        "  np.random.shuffle(train)\n",
        "  np.random.shuffle(val)\n",
        "  with open(os.path.join(f\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/{DATASET}\",f'train_{test_fold}fold_{DATASET}.txt'), 'w') as f:\n",
        "      f.write('\\n'.join(train))\n",
        "  with open(os.path.join(f\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/{DATASET}\",f'val_{test_fold}fold_{DATASET}.txt'), 'w') as f:\n",
        "    f.write('\\n'.join(val))\n",
        "  with open(os.path.join(f\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/{DATASET}\",f'test_{test_fold}fold_{DATASET}.txt'), 'w') as f:\n",
        "    f.write('\\n'.join(test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Aqd3JSC565e"
      },
      "source": [
        "FOLD SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohx2Zx6FySr4",
        "outputId": "51413808-7920-4ae9-9f2c-01f5d5a0bd10"
      },
      "source": [
        "import os\n",
        "folds = []\n",
        "selected_folds = 8\n",
        "for t in range(10): #(10 fold)\n",
        "  with open(os.path.join(\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/Multisampling16\",f'{t}_fold.txt'), 'r') as f:\n",
        "    folds.append(f.read().split('\\n'))\n",
        "print(folds[selected_folds][:5]) #Se dividio en 10 folds, y tomamos de a pares de 2. Uno para test y otro para val \n",
        "print(folds[selected_folds+1][:5])\n",
        "test = folds.pop(selected_folds) #se saca el primero, y despues el que queda en el lugar es el siguiente. Tomamos ese para validacion\n",
        "val = folds.pop(selected_folds)\n",
        "print(test[:5])\n",
        "print(val[:5])\n",
        "train = [item for sublist in folds for item in sublist]\n",
        "folds_name = f'{selected_folds}-{selected_folds+1}'\n",
        "with open(os.path.join(\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/Multisampling16\",f'train_{folds_name}folds_Multisampling16.txt'), 'w') as f:\n",
        "    f.write('\\n'.join(train))\n",
        "with open(os.path.join(\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/Multisampling16\",f'val_{folds_name}folds_Multisampling16.txt'), 'w') as f:\n",
        "  f.write('\\n'.join(val))\n",
        "with open(os.path.join(\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/Multisampling16\",f'test_{folds_name}folds_Multisampling16.txt'), 'w') as f:\n",
        "  f.write('\\n'.join(test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0_1_1_0.avi', '1_1_0_3.avi', '58_6_3_2.avi', '16_1_0_2.avi', '43_9_1_1.avi']\n",
            "['21_7_3_2.avi', '31_3_2_0.avi', '11_2_4_0.avi', '24_7_3_3.avi', '13_6_4_1.avi']\n",
            "['0_1_1_0.avi', '1_1_0_3.avi', '58_6_3_2.avi', '16_1_0_2.avi', '43_9_1_1.avi']\n",
            "['21_7_3_2.avi', '31_3_2_0.avi', '11_2_4_0.avi', '24_7_3_3.avi', '13_6_4_1.avi']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewPKWKnl6Jfx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOfSUWGw_O33"
      },
      "source": [
        "NORMALIZED SAMPLING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JvABbAO57Zh"
      },
      "source": [
        "\"\"\"\n",
        "based on frankibems repo github\n",
        "\"\"\"\n",
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import imageio\n",
        "import logging\n",
        "import argparse\n",
        "import numpy as np\n",
        "from multiprocessing import Process, JoinableQueue\n",
        "\n",
        "label_count = 64\n",
        "user_count = 10\n",
        "sample_count = 5\n",
        "\n",
        "\n",
        "#def get_logger():\n",
        "handler = logging.StreamHandler(stream=sys.stdout)\n",
        "logger = logging.getLogger('write_ctf')\n",
        "logger.setLevel(logging.INFO)\n",
        "logger.addHandler(handler)\n",
        "\n",
        "#    return logger\n",
        "\n",
        "\n",
        "def get_indices(frame_count, length):\n",
        "    \"\"\"\n",
        "    Returns a list of length 'reasonably' distributed indices\n",
        "    :param frame_count: The number of frames in a video\n",
        "    :param length: The number of frames to extract\n",
        "    :return: A list of indices\n",
        "    \"\"\"\n",
        "    \n",
        "    remainder_to_complete = (math.ceil(frame_count/length) * length) - frame_count    \n",
        "    try:\n",
        "      repeat_first_frames = np.random.randint(0, remainder_to_complete)\n",
        "      starting_cut = 0\n",
        "      repeat_last_frames = remainder_to_complete - repeat_first_frames\n",
        "    except (TypeError, ValueError):\n",
        "      #give some space for random sampling. e.i videos of frame_count 32 if length 32 will omit first x=0-4 frames, and start with x repeats of first frame\n",
        "      repeat_first_frames = np.random.randint(0,(frame_count // length) * 4) \n",
        "      starting_cut = repeat_first_frames\n",
        "      repeat_last_frames = 0\n",
        "    except:\n",
        "      return []\n",
        "    \n",
        "    #seria la nueva long incluyendo el principio y final repetido\n",
        "    width = (repeat_first_frames + frame_count + repeat_last_frames)// length\n",
        "    \n",
        "    \n",
        "    indices = []\n",
        "    frames = [0 for _ in range(repeat_first_frames)] + [i for i in range(frame_count)] + [frame_count -1 for _ in range(repeat_last_frames)]\n",
        "    #make videos not only vary in start but in middle frames\n",
        "    \n",
        "    start = np.random.randint(0, max(repeat_first_frames,1))\n",
        "    for i in range(length):\n",
        "      try:\n",
        "        indices.append(frames[min(i*width+start, length*width-1)])\n",
        "      except:\n",
        "        print(\"width\"+str(width))\n",
        "        print(\"length\"+str(length))\n",
        "        print(\"(repeat_first_frames + frame_count + repeat_last_frames)\"+str(repeat_first_frames + frame_count + repeat_last_frames))\n",
        "        break;\n",
        "    \n",
        "    \n",
        "    return indices\n",
        "\n",
        "\n",
        "def read_and_write_frames(label, user, sample, sequence_length, input_folder, output_folder, repeats):\n",
        "    \"\"\"\n",
        "    Reads frames for the given video and write to disk\n",
        "    \"\"\"\n",
        "    path = os.path.join(input_folder, '{}_{}_{}.mp4'.format(label, user, sample)) #OJO PORQUE CAMBIE LOS NOMBRES DE LOS VIDEOS\n",
        "    \n",
        "    for rep in range(repeats):\n",
        "      reader = imageio.get_reader(path)\n",
        "      length = reader.get_length()    \n",
        "      frames = []\n",
        "      \n",
        "      indices = get_indices(length, sequence_length)\n",
        "\n",
        "      if indices == []:\n",
        "        logger.info(\"Something happened with {:0>3}_{:0>3}_{:0>3}.mp4\".format(label + 1, user + 1, sample + 1))\n",
        "        return\n",
        "\n",
        "      for i in indices:\n",
        "          frames.append(reader.get_data(i))\n",
        "      reader.close()        \n",
        "      fourcc = cv2.VideoWriter_fourcc(*'XVID')    \n",
        "      path = os.path.join(output_folder, '{}_{}_{}_{}.avi'.format(label, user, sample, rep))\n",
        "      out = cv2.VideoWriter(path, fourcc, 10.0, (1920,1080))\n",
        "      # Write frames to output folder\n",
        "      for frame in frames:        \n",
        "          out.write(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "      out.release()\n",
        "\n",
        "def worker_method(queue, sequence_length, input_folder, output_folder,repeats):\n",
        "    #logger = get_logger()\n",
        "    while True:\n",
        "        item = queue.get()\n",
        "        if item is None:\n",
        "            queue.task_done()\n",
        "            break\n",
        "\n",
        "        read_and_write_frames(item[0], item[1], item[2], sequence_length, input_folder, output_folder,repeats)\n",
        "        logger.info('Processed {}_{}_{}.mp4'.format(item[0], item[1], item[2]))\n",
        "        queue.task_done()\n",
        "\n",
        "\n",
        "def main(sequence_length, num_procs, input_folder, output_folder, repeats):\n",
        "    # Create output directory if it does not exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    queue = JoinableQueue()\n",
        "    for label in range(label_count):\n",
        "        for user in range(user_count):\n",
        "            for sample in range(sample_count):\n",
        "                queue.put((label, user, sample))\n",
        "\n",
        "    # None will signal process stop\n",
        "    for _ in range(num_procs):\n",
        "        queue.put(None)\n",
        "\n",
        "    workers = []\n",
        "    for _ in range(num_procs):\n",
        "        worker = Process(target=worker_method, args=(queue, sequence_length, input_folder, output_folder, repeats))\n",
        "        workers.append(worker)\n",
        "        worker.start()\n",
        "\n",
        "    queue.join()\n",
        "    print('Done.')\n",
        "\n",
        "\n",
        "sequence_length = 16\n",
        "num_procs=2\n",
        "input_folder = \"/content/gdrive/My Drive/Informática/Tesina/Videos/Originals\"\n",
        "output_folder  = \"/content/gdrive/My Drive/Informática/Tesina/Videos/Multisampling16\"\n",
        "repeats = 4\n",
        "main(sequence_length, num_procs, input_folder, output_folder, repeats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmNf2a0d_Tdt"
      },
      "source": [
        "SIMPLE SAMPLING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dye0-gsxz0VY"
      },
      "source": [
        "\n",
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import imageio\n",
        "import logging\n",
        "import argparse\n",
        "import numpy as np\n",
        "from multiprocessing import Process, JoinableQueue\n",
        "\n",
        "label_count = 64\n",
        "user_count = 10\n",
        "sample_count = 5\n",
        "\n",
        "\n",
        "#def get_logger():\n",
        "handler = logging.StreamHandler(stream=sys.stdout)\n",
        "logger = logging.getLogger('write_ctf')\n",
        "logger.setLevel(logging.INFO)\n",
        "logger.addHandler(handler)\n",
        "\n",
        "#    return logger\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import imageio\n",
        "import logging\n",
        "import argparse\n",
        "import numpy as np\n",
        "from multiprocessing import Process, JoinableQueue\n",
        "\n",
        "label_count = 64\n",
        "user_count = 10\n",
        "sample_count = 5\n",
        "\n",
        "\n",
        "def get_logger():\n",
        "    handler = logging.StreamHandler(stream=sys.stdout)\n",
        "    logger = logging.getLogger('write_ctf')\n",
        "    logger.setLevel(logging.INFO)\n",
        "    logger.addHandler(handler)\n",
        "\n",
        "    return logger\n",
        "\n",
        "\n",
        "def get_indices(frame_count, length):\n",
        "    \"\"\"\n",
        "    Returns a list of length 'reasonably' distributed indices\n",
        "    :param frame_count: The number of frames in a video\n",
        "    :param length: The number of frames to extract\n",
        "    :return: A list of indices\n",
        "    \"\"\"\n",
        "    assert frame_count >= length, 'frame_count ({}) must be >= length ({})'.format(frame_count, length)\n",
        "\n",
        "    width = frame_count / length\n",
        "    start = np.random.randint(0, width, 1)[0]\n",
        "\n",
        "    width = math.floor(width)\n",
        "\n",
        "    indices = [start]\n",
        "    for i in range(1, length):\n",
        "        indices.append(indices[-1] + width)\n",
        "\n",
        "\n",
        "    return indices\n",
        "\n",
        "\n",
        "def read_and_write_frames(label, user, sample, sequence_length, input_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Reads frames for the given video and write to disk\n",
        "    \"\"\"\n",
        "    path = os.path.join(input_folder, '{}_{}_{}.mp4'.format(label, user, sample))\n",
        "\n",
        "    frames = []\n",
        "    reader = imageio.get_reader(path)\n",
        "    length = reader.get_length()\n",
        "\n",
        "    if length < sequence_length:\n",
        "        indices = range(length)\n",
        "    else:\n",
        "        indices = get_indices(length, sequence_length)\n",
        "    \n",
        "    for i in indices:\n",
        "      frames.append(reader.get_data(i))\n",
        "    # Pad with copies of the last frame if length < sequence_length\n",
        "    padding = sequence_length - length\n",
        "    if padding > 0:\n",
        "        last = frames[-1]\n",
        "        for i in range(padding):\n",
        "            frames.append(np.copy(last))\n",
        "\n",
        "    # Write frames to output folder\n",
        "    \n",
        "    reader.close()        \n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')    \n",
        "    path = os.path.join(output_folder, '{}_{}_{}.avi'.format(label, user, sample))\n",
        "    out = cv2.VideoWriter(path, fourcc, 10.0, (1920,1080))\n",
        "    # Write frames to output folder\n",
        "    for frame in frames:        \n",
        "        out.write(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "    out.release()\n",
        "\n",
        "\n",
        "def worker_method(queue, sequence_length, input_folder, output_folder):\n",
        "    logger = get_logger()\n",
        "    while True:\n",
        "        item = queue.get()\n",
        "        if item is None:\n",
        "            queue.task_done()\n",
        "            break\n",
        "\n",
        "        read_and_write_frames(item[0], item[1], item[2], sequence_length, input_folder, output_folder)\n",
        "        logger.info('Processed {}_{}_{}.mp4'.format(item[0] + 1, item[1] + 1, item[2] + 1))\n",
        "        queue.task_done()\n",
        "\n",
        "\n",
        "def main(sequence_length, num_procs, input_folder, output_folder):\n",
        "    # Create output directory if it does not exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    queue = JoinableQueue()\n",
        "    for label in range(label_count):\n",
        "        for user in range(user_count):\n",
        "            for sample in range(sample_count):\n",
        "                queue.put((label, user, sample))\n",
        "\n",
        "    # None will signal process stop\n",
        "    for i in range(num_procs):\n",
        "        queue.put(None)\n",
        "\n",
        "    workers = []\n",
        "    for i in range(num_procs):\n",
        "        worker = Process(target=worker_method, args=(queue, sequence_length, input_folder, output_folder))\n",
        "        workers.append(worker)\n",
        "        worker.start()\n",
        "\n",
        "    queue.join()\n",
        "    print('Done.')\n",
        "\n",
        "sequence_length = 32\n",
        "num_procs=2\n",
        "input_folder = \"/content/gdrive/My Drive/Informática/Tesina/Videos/Originals\"\n",
        "output_folder  = \"/content/gdrive/My Drive/Informática/Tesina/Videos/SimpleSampling32\"\n",
        "main(sequence_length, num_procs, input_folder, output_folder)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-fWwDW1i-3R"
      },
      "source": [
        "CROPPER \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN4auzBpZbze"
      },
      "source": [
        "import os \n",
        "import numpy as np\n",
        "import cv2\n",
        "with open(os.path.join(\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/SimpleSampling32\",'train_0-1folds_SimpleSampling32.txt'), 'r') as f:\n",
        "  train = f.read().split(\"\\n\")\n",
        "with open(os.path.join(\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/SimpleSampling32\",'val_0-1folds_SimpleSampling32.txt'), 'r') as f:\n",
        "  val = f.read().split(\"\\n\")\n",
        "with open(os.path.join(\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/SimpleSampling32\",'test_0-1folds_SimpleSampling32.txt'), 'r') as f:\n",
        "  test = f.read().split(\"\\n\")\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNPUsA5okEnj"
      },
      "source": [
        "height_upper_limit = int(1080/4)\n",
        "width_upper_limit = int(1920/4)\n",
        "height_to_crop = int(height_upper_limit*3)\n",
        "width_to_crop = int(width_upper_limit*3)\n",
        "train_cropped = list(map(lambda n: \" \".join([n, str(np.random.randint(0, width_upper_limit)),str(np.random.randint(0, height_upper_limit))] ), train))\n",
        "val_cropped = list(map(lambda n: \" \".join([n, str(np.random.randint(0, width_upper_limit)),str(np.random.randint(0, height_upper_limit))] ), val))\n",
        "test_cropped = list(map(lambda n: \" \".join([n, str(np.random.randint(0, width_upper_limit)),str(np.random.randint(0, height_upper_limit))] ), test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzlfF-CUN1KV"
      },
      "source": [
        "with open(os.path.join(\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/SimpleSampling32\",'train_0-1folds_SimpleSampling32Cropped.txt'), 'w') as f:\n",
        "    f.write('\\n'.join(train_cropped))\n",
        "with open(os.path.join(\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/SimpleSampling32\",'val_0-1folds_SimpleSampling32Cropped.txt'), 'w') as f:\n",
        "  f.write('\\n'.join(val_cropped))\n",
        "with open(os.path.join(\"/content/gdrive/My Drive/Informática/Tesina/DatasetsNames/SimpleSampling32\",'test_0-1folds_SimpleSampling32Cropped.txt'), 'w') as f:\n",
        "  f.write('\\n'.join(test_cropped))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AG9MMN8rDDN"
      },
      "source": [
        "#Checkout cropped videos\n",
        "for vid in mini:\n",
        "  fname, w_limit, h_limit = vid.split(\" \")\n",
        "  print(\"Processing \"+fname)\n",
        "  w_limit, h_limit = int(w_limit), int(h_limit)\n",
        "  vidcap = cv2.VideoCapture('/content/gdrive/My Drive/Informática/Tesina/Videos/Multisampling32/'+fname)    \n",
        "  frames = []\n",
        "  suc, frame = vidcap.read()\n",
        "  while suc:\n",
        "    frames.append(frame[h_limit:h_limit+height_to_crop,w_limit:w_limit+width_to_crop :])\n",
        "    suc, frame = vidcap.read()    \n",
        "  fourcc = cv2.VideoWriter_fourcc('F', 'M', 'P', '4')\n",
        "  h, w, c = frames[0].shape\n",
        "  out = cv2.VideoWriter(fname, fourcc, 5.0,(w,h))\n",
        "  for i in range(len(frames)):        \n",
        "    out.write(frames[i])          \n",
        "  out.release()            \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vsmqqWG-wTg"
      },
      "source": [
        "HSV dataset maker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvXhRlE7C1q8"
      },
      "source": [
        "import pickle as pkl\n",
        "with open('missing.pickle', 'rb') as f:\n",
        "  files = pkl.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juo06If9_qkP",
        "outputId": "80b231d8-e32d-471c-d915-1b83581094b1"
      },
      "source": [
        "import os \n",
        "import numpy as np\n",
        "import cv2\n",
        "import math\n",
        "\n",
        "greenH = math.ceil(112 / 2)\n",
        "greenS = math.ceil(255 * 69/100)\n",
        "greenV = math.ceil(255 * 78/100)\n",
        "#red\n",
        "redH = math.ceil(349 / 2)\n",
        "redS = math.ceil(255 * 69/100)\n",
        "redV = math.ceil(255 * 53/100)\n",
        "range_green = 62 #62\n",
        "lower_green = np.array([greenH-range_green,greenS-range_green,greenV-range_green])\n",
        "upper_green = np.array([greenH+range_green,greenS+range_green,greenV+range_green])\n",
        "range_red = 58\n",
        "lower_red = np.array([redH-range_red,redS-range_red,redV-range_red])\n",
        "upper_red = np.array([redH+range_red,redS+range_red,redV+range_red])\n",
        "\n",
        "files = os.listdir('/content/gdrive/My Drive/Informática/Tesina/Videos/Multisampling32/')\n",
        "print(len(files))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSmmTVseCwyr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAPDAYs4WQsO"
      },
      "source": [
        "from multiprocessing import Pool\n",
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "greenH = math.ceil(112 / 2)\n",
        "greenS = math.ceil(255 * 69/100)\n",
        "greenV = math.ceil(255 * 78/100)\n",
        "#red\n",
        "redH = math.ceil(349 / 2)\n",
        "redS = math.ceil(255 * 69/100)\n",
        "redV = math.ceil(255 * 53/100)\n",
        "range_green = 62 #62\n",
        "lower_green = np.array([greenH-range_green,greenS-range_green,greenV-range_green])\n",
        "upper_green = np.array([greenH+range_green,greenS+range_green,greenV+range_green])\n",
        "range_red = 58\n",
        "lower_red = np.array([redH-range_red,redS-range_red,redV-range_red])\n",
        "upper_red = np.array([redH+range_red,redS+range_red,redV+range_red])\n",
        "\n",
        "\n",
        "def toHSV(fname):\n",
        "  print(\"Processing \"+fname)  \n",
        "  vidcap = cv2.VideoCapture('/content/gdrive/My Drive/Informática/Tesina/Videos/Multisampling32/'+fname)    \n",
        "  frames = []\n",
        "  suc, frame = vidcap.read()\n",
        "  while suc:\n",
        "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)             \n",
        "    mask_green = cv2.inRange(hsv, lower_green, upper_green)\n",
        "    mask_red = cv2.inRange(hsv, lower_red, upper_red)\n",
        "    mask = np.bitwise_or(mask_green,mask_red)\n",
        "    frame = cv2.bitwise_and(frame,frame, mask= mask)    \n",
        "    frames.append(frame)        \n",
        "    suc, frame = vidcap.read()\n",
        "  fourcc = cv2.VideoWriter_fourcc('F', 'M', 'P', '4')\n",
        "  h, w, c = frames[0].shape\n",
        "  out = cv2.VideoWriter(os.path.join('/content/gdrive/My Drive/Informática/Tesina/Videos/HSV',fname), fourcc, 10.0,(w,h))\n",
        "  for i in range(len(frames)):        \n",
        "    out.write(frames[i])          \n",
        "  out.release()            \n",
        "\n",
        "def main(num_procs,  output_folder):\n",
        "  if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "  with Pool(processes=num_procs) as pool:\n",
        "    pool.map(toHSV, files)\n",
        "    \n",
        "main(4, '/content/gdrive/My Drive/Informática/Tesina/Videos/HSV')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwETr43BELHH",
        "outputId": "3f4b617d-7fd0-49f7-a60e-470179ca9338"
      },
      "source": [
        "len(os.listdir('/content/gdrive/My Drive/Informática/Tesina/Videos/HSV'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy2zZ0-SJU51"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}