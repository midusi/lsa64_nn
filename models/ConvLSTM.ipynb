{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "znuik6QlSIlx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff98aaf9-dc25-4780-a024-0c1e29fdeb88"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/') \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owHW6xBk6XG0"
      },
      "source": [
        "CALLBACKS\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE5BbQBK4FJe"
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "class MyCheckpoint(Callback):\n",
        "  def __init__(self, start_epoch, exp_folder, weights_path, pickles_path, EXP_NAME, model_name):\n",
        "    super(MyCheckpoint, self).__init__()\n",
        "    self.current_epoch = start_epoch + 1  \n",
        "    self.timestamps = {}\n",
        "    self.exp_folder = exp_folder\n",
        "    self.weights_path = weights_path\n",
        "    self.pickles_path = pickles_path\n",
        "    self.EXP_NAME = EXP_NAME  \n",
        "    self.model_name = model_name\n",
        "    self.model_training_time = 0\n",
        "    self.start_batch = 0\n",
        "    self.end_batch = 0\n",
        "\n",
        "\n",
        "  def on_epoch_begin(self, epoch, logs=None):\n",
        "    self.timestamps[self.current_epoch] = {}   \n",
        "    self.timestamps[self.current_epoch][\"start\"] = datetime.now().time().strftime(\"%H:%M\")  \n",
        "\n",
        "  def on_test_begin(self, logs=None):    \n",
        "    self.timestamps[self.current_epoch][\"end\"] = datetime.now().time().strftime(\"%H:%M\")  # PASAR ARRIBA POR EL SAVE\n",
        "    self.timestamps[self.current_epoch][\"train_time\"] = self.model_training_time \n",
        "    with open(os.path.join(self.exp_folder, f\"timestamps_epoch{self.current_epoch}.pickle\"), 'wb') as fd:\n",
        "      pickle.dump(self.timestamps, fd)\n",
        "    self.model_training_time = 0\n",
        "    self.model.save_weights(os.path.join(self.weights_path+'{}_epoch_{}.h5'.format(self.model_name,self.current_epoch)))          \n",
        "\n",
        "  def on_train_batch_begin(self, batch, logs=None):\n",
        "      self.start_batch = time.time()\n",
        "\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "      self.end_batch = time.time()\n",
        "      self.model_training_time+= (self.end_batch - self.start_batch)\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):            \n",
        "    with open(os.path.join(self.pickles_path+'{}_epoch_{}.pickle'.format(self.model_name,self.current_epoch)), 'wb') as fd:\n",
        "      pickle.dump(logs, fd)\n",
        "    self.current_epoch = self.current_epoch + 1    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqcMZuUZ0Z4k"
      },
      "source": [
        "EXPERIMENT OBJECT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1vAqV-05DlX"
      },
      "source": [
        "FOLD_NAME = '0fold'\n",
        "DATASET = 'Multisampling32'\n",
        "MODEL_NAME='rgb128_'+FOLD_NAME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msLIc5_rhzmy"
      },
      "source": [
        "import os\n",
        "from tensorflow.keras.initializers import HeNormal, GlorotNormal\n",
        "from tensorflow.keras.regularizers import l1_l2,l1, l2\n",
        "from tensorflow.keras.activations import elu, tanh\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
        "\n",
        "basePath = \"/content/gdrive/My Drive/Informática/Tesina/\"\n",
        "\n",
        "datasets = {            \n",
        "            \"Multisampling32\":{\"path\": basePath+\"Videos/Multisampling32/\",\"num_frames\": 32,\"files_posfix\":\"Multisampling32\"},  \n",
        "            \"Multisampling16\":{\"path\": basePath+\"Videos/Multisampling16/\",\"num_frames\": 16, \"files_posfix\":\"Multisampling16\"},  \n",
        "            \"Multisampling8\":{\"path\": basePath+\"Videos/Multisampling8/\",\"num_frames\": 8, \"files_posfix\":\"Multisampling8\"},  \n",
        "            \"SimpleSampling32\":{\"path\": basePath+\"Videos/SimpleSampling32/\",\"num_frames\": 32, \"files_posfix\":\"SimpleSampling32\"},\n",
        "            \"HSV\":{\"path\": \"/content/gdrive/My Drive/Informática/Tesina/Videos/HSV/\", \"num_frames\":32,\"files_posfix\":\"Multisampling32\" }              \n",
        "  }\n",
        "class Experiment():\n",
        "\n",
        "  def __init__(self, exp_name, model_name):\n",
        "    #Logging and checkpoints\n",
        "    self.EXP_NAME = exp_name\n",
        "    self.model_name = model_name\n",
        "    self.exp_folder = os.path.join(basePath+\"Experimentos/ConvLSTM\", exp_name, model_name)\n",
        "    self.weights_path = os.path.join(self.exp_folder,\"Weights/\")\n",
        "    self.pickles_path = os.path.join(self.exp_folder,\"Pickles/\")\n",
        "    if (os.path.exists(self.exp_folder)):           \n",
        "      weights = os.listdir(self.weights_path)\n",
        "      # get the latest epoch trained\n",
        "      try:\n",
        "        self.current_epoch = sorted(list(map(lambda x: int(x.split('_')[-1].split('.')[0]), weights)), reverse=True)[0] \n",
        "      except (TypeError, IndexError):\n",
        "        self.current_epoch = 0      \n",
        "    else:      \n",
        "      os.mkdir(self.exp_folder)      \n",
        "      os.mkdir(self.weights_path)\n",
        "      os.mkdir(self.pickles_path)\n",
        "      self.current_epoch = 0\n",
        "\n",
        "    tensorboard = TensorBoard(log_dir=os.path.join(self.exp_folder, 'logs'), histogram_freq=1)\n",
        "    early = EarlyStopping(monitor='val_accuracy', patience=5)\n",
        "    self.testing = False\n",
        "    #Data specs\n",
        "    data_dict = datasets[self.EXP_NAME]\n",
        "    self.fold_name = FOLD_NAME\n",
        "    self.files_posfix = data_dict['files_posfix']\n",
        "    self.names_path = os.path.join(basePath+\"/DatasetsNames\", data_dict['files_posfix'])\n",
        "    self.videos_path =  data_dict['path'] \n",
        "    self.num_frames = data_dict['num_frames']\n",
        "    self.height = 128 \n",
        "    self.width = 128 \n",
        "    self.channels = 3\n",
        "    #Model specs\n",
        "    self.activation = tanh\n",
        "    self.initializer = GlorotNormal\n",
        "    self.regularizer = None#l2(1e-4)\n",
        "    self.conv_blocks = [\n",
        "                        {'filters':16, 'kernel_size':5, 'pool_size':2},\n",
        "                        {'filters':16, 'kernel_size':5, 'pool_size':2},\n",
        "                        {'filters':32, 'kernel_size':5, 'pool_size':2},  \n",
        "                        {'filters':64, 'kernel_size':5, 'pool_size':2},  \n",
        "                    ]\n",
        "\n",
        "\n",
        "    self.batch_size = 32\n",
        "    self.epochs_to_train = 28 - self.current_epoch\n",
        "    self.lr = 0.001\n",
        "    self.callbacks = [MyCheckpoint(self.current_epoch, self.exp_folder, self.weights_path, self.pickles_path, self.EXP_NAME, self.model_name), tensorboard, early]\n",
        "    \n",
        "      \n",
        "\n",
        "  def save_resume(self):\n",
        "    with open(os.path.join(self.exp_folder,'exp_resume.txt'), 'w') as f:\n",
        "      stri = \"\"\n",
        "      settings = [a for a in dir(experiment) if not a.startswith('__') and not callable(getattr(experiment, a))]\n",
        "      for setting in settings:\n",
        "        stri = stri + setting+\": \"+str(getattr(experiment, setting))+'\\n'\n",
        "      f.writelines(stri)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PZtHwd7OsN6"
      },
      "source": [
        "MODELOS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGDPLWIeOr4H"
      },
      "source": [
        "\n",
        "from tensorflow.keras.layers import Input, ConvLSTM2D, BatchNormalization, MaxPooling3D, Flatten, Dense, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "\n",
        "def conv_lstm_block(input,index,filters, kernel_size, activation,initializer,regularizer, pool_size):\n",
        "  conv = ConvLSTM2D(\n",
        "      filters=filters, \n",
        "      kernel_size=(kernel_size,kernel_size),      \n",
        "      activation=activation, \n",
        "      kernel_initializer=initializer(),\n",
        "      kernel_regularizer=regularizer, \n",
        "      padding='same',\n",
        "      return_sequences=True,\n",
        "      name=f\"Conv_{index}\")(input)\n",
        "  batch = BatchNormalization(name=f\"Batch_{index}\")(conv)\n",
        "  pooling = MaxPooling3D(pool_size=(pool_size,pool_size,pool_size), padding='same',name=f\"3dPool_{index}\")(batch)  \n",
        "  return pooling\n",
        "\n",
        "def last_conv_lstm_block(input,filters, kernel_size, activation,initializer,regularizer, pool_size):\n",
        "  conv = ConvLSTM2D(\n",
        "      filters=filters, \n",
        "      kernel_size=(kernel_size,kernel_size),      \n",
        "      activation=activation, \n",
        "      kernel_initializer=initializer(),\n",
        "      kernel_regularizer=regularizer, \n",
        "      padding='same',\n",
        "      return_sequences=False,\n",
        "      name=\"final_conv\")(input) #La proxima entonces toma solo lo ultimo\n",
        "  batch = BatchNormalization(name=\"final_batch\")(conv)\n",
        "  pooling = MaxPooling2D(pool_size=(pool_size,pool_size),padding='same', name=\"final_pool\")(batch)\n",
        "  avg_pooling = AveragePooling2D()(pooling)\n",
        "  flat = Flatten()(avg_pooling)  \n",
        "  return flat\n",
        "\n",
        "def conv_stack(input, experiment):\n",
        "  stack = input\n",
        "  for i in range(1,len(experiment.conv_blocks)):\n",
        "    stack = conv_lstm_block(stack,i,\n",
        "      experiment.conv_blocks[i]['filters'],\n",
        "      experiment.conv_blocks[i]['kernel_size'],\n",
        "      experiment.activation,\n",
        "      experiment.initializer,\n",
        "      experiment.regularizer,\n",
        "      experiment.conv_blocks[i]['pool_size']\n",
        "    )\n",
        "  stack = last_conv_lstm_block(stack,\n",
        "      experiment.conv_blocks[-1]['filters'],\n",
        "      experiment.conv_blocks[-1]['kernel_size'],\n",
        "      experiment.activation,\n",
        "      experiment.initializer,\n",
        "      experiment.regularizer,\n",
        "      experiment.conv_blocks[-1]['pool_size']\n",
        "  )\n",
        "  return stack\n",
        "\n",
        "def ConvLSTM_model(experiment,categories=64):\n",
        "  input = Input(shape=(32, experiment.height, experiment.width,experiment.channels))\n",
        "  stack = conv_stack(input, experiment)\n",
        "  output = Dense(categories, activation='softmax')(stack)\n",
        "  model = Model(inputs=input, outputs=output, name=experiment.model_name)  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XbpfKIzO3wk"
      },
      "source": [
        "GENERADOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw9g3NkoaqML"
      },
      "source": [
        "import cv2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "def generator(videos_path, samples, batch_size, categories=64):\n",
        "  \"\"\"\n",
        "    samples serian los nombres de archivos\n",
        "  \"\"\"\n",
        "  w = experiment.width\n",
        "  h = experiment.height\n",
        "  num_samples = len(samples) \n",
        "  while True:\n",
        "    for offset in range(0,num_samples, batch_size):\n",
        "      batch_samples = samples[offset:offset+batch_size]\n",
        "      X_train = []\n",
        "      y_train = []\n",
        "      for batch_sample in batch_samples:\n",
        "        vidcap = cv2.VideoCapture(os.path.join(videos_path,batch_sample))      \n",
        "        frames = []\n",
        "        suc, frame = vidcap.read()        \n",
        "        while suc: \n",
        "          frame = cv2.resize(frame, (w,h), interpolation=cv2.INTER_AREA)\n",
        "          frame =  cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) if (experiment.channels==3) else np.expand_dims(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY),2)\n",
        "          frame = frame.astype(np.float32)\n",
        "          frame /= 255.0          \n",
        "          frames.append(frame)\n",
        "          suc, frame = vidcap.read()        \n",
        "        X_train.append(frames)                \n",
        "        cat = int(batch_sample.split('_')[0])#  Los mp4 estan categorizados de 1 a 64 y los .avi de 0 a 64, asi que no necesito restar 1        \n",
        "        y_train.append(to_categorical(cat, num_classes=categories))               \n",
        "      try: \n",
        "        X_train = np.asarray(X_train, dtype=np.float32)      \n",
        "      except:\n",
        "        print(\"frames len: \"+str(len(frames)))\n",
        "        try:\n",
        "          print(\"Intentando de vuelta\")\n",
        "          X_train = np.asarray(X_train, dtype=np.float32)      \n",
        "        except:\n",
        "          print(len(X_train))\n",
        "        print(\"Long de video: \"+str(vidcap.get(7)))\n",
        "      y_train = np.asarray(y_train)      \n",
        "      yield X_train, y_train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30Ih9jKkSxC7"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import math \n",
        "class SequenceGenerator(Sequence):\n",
        "  def __init__(self, videos_path, samples,batch_size, width, height, channels):\n",
        "    self.batch_size = batch_size\n",
        "    self.videos_path = videos_path\n",
        "    self.samples = samples\n",
        "    self.width = width\n",
        "    self.height = height\n",
        "    self.channels = channels\n",
        "    self.len = len(os.listdir(videos_path))\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    batch_samples = self.samples[idx * self.batch_size:(idx+1)*self.batch_size]\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    for batch_sample in batch_samples:      \n",
        "      vidcap = cv2.VideoCapture(os.path.join(self.videos_path,batch_sample))              \n",
        "      frames = []\n",
        "      suc, frame = vidcap.read()              \n",
        "      while suc: \n",
        "        frame = cv2.resize(frame, (self.width,self.height), interpolation=cv2.INTER_AREA)\n",
        "        frame =  cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) if (self.channels==3) else np.expand_dims(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY),2)\n",
        "        frame = frame.astype(np.float32)\n",
        "        frame /= 255.0          \n",
        "        frames.append(frame)\n",
        "        suc, frame = vidcap.read()      \n",
        "      \n",
        "      X_train.append(frames)        \n",
        "      cat = int(batch_sample.split('_')[0])#  Los mp4 estan categorizados de 1 a 64 y los .avi de 0 a 64, asi que no necesito restar 1        \n",
        "      y_train.append(to_categorical(cat, num_classes=64))      \n",
        "        \n",
        "    X_train = np.asarray(X_train, dtype=np.float32)      \n",
        "    y_train = np.asarray(y_train)      \n",
        "    return X_train, y_train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIaJWpOR6XGu"
      },
      "source": [
        "Inicializacion\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LJzzs4MyEgc",
        "outputId": "9df2ae3c-4f79-4071-88a2-014b14dc09bf"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "def changeTestName(test_names):\n",
        "  for i in range(len(test_names)):\n",
        "    test_names_cleaned = list(map(lambda sample: \"_\".join(sample.split('_')[:-1])+\".mp4\", test_names))\n",
        "  return list(set(test_names_cleaned))\n",
        "def changeToavi(test_names):\n",
        "  test_names_cleaned = list(map(lambda sample: sample.split('.')[0]+\".avi\", test_names))\n",
        "  return test_names_cleaned\n",
        "def changeTomp4(test_names):\n",
        "  test_names_cleaned = list(map(lambda sample: sample.split('.')[0]+\".mp4\", test_names))\n",
        "  return test_names_cleaned\n",
        "\"\"\"\n",
        "print(os.listdir(\"/content/gdrive/My Drive/Informática/Tesina/Experimentos/ConvLSTM\"))\n",
        "print(\"Ingrese el nombre del experimento: \")\n",
        "exp_name = input()\n",
        "if not os.path.exists(os.path.join(\"/content/gdrive/My Drive/Informática/Tesina/Experimentos/ConvLSTM\", exp_name)):\n",
        "  os.mkdir(os.path.join(\"/content/gdrive/My Drive/Informática/Tesina/Experimentos/ConvLSTM\", exp_name))\n",
        "print(os.listdir(os.path.join(\"/content/gdrive/My Drive/Informática/Tesina/Experimentos/ConvLSTM\", exp_name)))\n",
        "print(\"Nombre de modelo [Baseline]: \")\n",
        "model_name = input()\n",
        "model_name = \"baseline\" if model_name == '' else model_name\n",
        "\"\"\"\n",
        "experiment = Experiment(DATASET, MODEL_NAME)\n",
        "experiment.save_resume()\n",
        "weights_path = experiment.weights_path\n",
        "pickles_path = experiment.pickles_path\n",
        "videos_path = experiment.videos_path\n",
        "print(DATASET)\n",
        "print(MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multisampling32\n",
            "rgb128_0fold\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHHFMLafEzS5"
      },
      "source": [
        "Train val test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzQ7DYRpE4eP"
      },
      "source": [
        "\n",
        "with open(os.path.join(experiment.names_path,f'train_{experiment.fold_name}_{experiment.files_posfix}.txt'), 'r') as f:\n",
        "  train = f.read().split('\\n')\n",
        "with open(os.path.join(experiment.names_path,f'val_{experiment.fold_name}_{experiment.files_posfix}.txt'), 'r') as f:\n",
        "  val = f.read().split('\\n')\n",
        "with open(os.path.join(experiment.names_path,f'test_{experiment.fold_name}_{experiment.files_posfix}.txt'), 'r') as f:\n",
        "  test = f.read().split('\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrkRDEHME5eM"
      },
      "source": [
        "\n",
        "Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEnbOyVNET27"
      },
      "source": [
        "def get_model_memory_usage(batch_size, model):\n",
        "    import numpy as np\n",
        "    try:\n",
        "        from keras import backend as K\n",
        "    except:\n",
        "        from tensorflow.keras import backend as K\n",
        "\n",
        "    shapes_mem_count = 0\n",
        "    internal_model_mem_count = 0\n",
        "    for l in model.layers:\n",
        "        layer_type = l.__class__.__name__\n",
        "        if layer_type == 'Model':\n",
        "            internal_model_mem_count += get_model_memory_usage(batch_size, l)\n",
        "        single_layer_mem = 1\n",
        "        out_shape = l.output_shape\n",
        "        if type(out_shape) is list:\n",
        "            out_shape = out_shape[0]\n",
        "        for s in out_shape:\n",
        "            if s is None:\n",
        "                continue\n",
        "            single_layer_mem *= s\n",
        "        shapes_mem_count += single_layer_mem\n",
        "\n",
        "    trainable_count = np.sum([K.count_params(p) for p in model.trainable_weights])\n",
        "    non_trainable_count = np.sum([K.count_params(p) for p in model.non_trainable_weights])\n",
        "\n",
        "    number_size = 4.0\n",
        "    if K.floatx() == 'float16':\n",
        "        number_size = 2.0\n",
        "    if K.floatx() == 'float64':\n",
        "        number_size = 8.0\n",
        "\n",
        "    total_memory = number_size * (batch_size * shapes_mem_count + trainable_count + non_trainable_count)\n",
        "    gbytes = np.round(total_memory / (1024.0 ** 3), 3) + internal_model_mem_count\n",
        "    return gbytes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8ldQ9p-EUez",
        "outputId": "127542d7-d2d4-4e1f-f17e-559be8590517"
      },
      "source": [
        "get_model_memory_usage(32, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.987"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fULlgn_O7Ub1",
        "outputId": "e7ab7cf0-e80b-44c0-f8dd-c53749a1d003"
      },
      "source": [
        "\n",
        "batch_size = experiment.batch_size\n",
        "\n",
        "#NO GUARDO MODELO POR AHORA\n",
        "\n",
        "#if f\"{experiment.model_name}.pickle\" in os.listdir(experiment.exp_folder):  \n",
        "#  with open(os.path.join(experiment.exp_folder, f\"{experiment.model_name}.pickle\"), 'rb') as pklfile:\n",
        "#    conf = pickle.load(pklfile)    \n",
        "#    model = Model.from_config(conf)\n",
        "#else:\n",
        "model = ConvLSTM_model(experiment)\n",
        "  #with open(os.path.join(experiment.exp_folder, f\"{experiment.model_name}.pickle\"), 'wb') as pklfile:\n",
        "  #  conf = model.get_config()\n",
        "  #  pickle.dump(conf, pklfile)\n",
        "\n",
        "\n",
        "\n",
        "with open(os.path.join(experiment.exp_folder, 'summary.txt'), 'w') as f:\n",
        "  model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
        "\n",
        "if '{}_epoch_{}.h5'.format(experiment.model_name, experiment.current_epoch) in os.listdir(weights_path):\n",
        "  model.load_weights(os.path.join(experiment.weights_path,'{}_epoch_{}.h5'.format(experiment.model_name, experiment.current_epoch)))\n",
        "\n",
        "adam = Adam(learning_rate=experiment.lr)\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "if experiment.testing:\n",
        "  print(\"Estas seguro que queres testear? [y/n]\")\n",
        "  if (input() == 'y'):    \n",
        "    eval_dict = model.evaluate(\n",
        "        generator(videos_path,test, 1)\n",
        "      , steps=int(len(test)/1)\n",
        "      , batch_size=1\n",
        "      , verbose = 1\n",
        "      , return_dict=True\n",
        "    )\n",
        "    with open(os.path.join(experiment.exp_folder, f'evaluation_epoch{experiment.current_epoch}_{experiment.num_frames}.pickle'), 'wb') as pkl:\n",
        "      pickle.dump(eval_dict, pkl)\n",
        "  else: \n",
        "    print(\"Cambia el experimento entonces en experiment.testing\")\n",
        "else:\n",
        "  train_gen = SequenceGenerator(videos_path, train, batch_size, experiment.width, experiment.height, experiment.channels)    \n",
        "  val_gen = SequenceGenerator(videos_path, val, batch_size, experiment.width, experiment.height, experiment.channels)    \n",
        "  history = model.fit(\n",
        "    train_gen\n",
        "    , steps_per_epoch=int(len(train)/batch_size)\n",
        "    , validation_data = val_gen\n",
        "    ,validation_steps = int(len(val)/batch_size)\n",
        "    , epochs = experiment.epochs_to_train\n",
        "    , verbose = 1\n",
        "    , shuffle = False    \n",
        "    , callbacks=list(experiment.callbacks)\n",
        "    , use_multiprocessing=True\n",
        "      ,workers=4\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"rgb128_0fold\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 128, 128, 3)] 0         \n",
            "_________________________________________________________________\n",
            "Conv_1 (ConvLSTM2D)          (None, 32, 128, 128, 16)  30464     \n",
            "_________________________________________________________________\n",
            "Batch_1 (BatchNormalization) (None, 32, 128, 128, 16)  64        \n",
            "_________________________________________________________________\n",
            "3dPool_1 (MaxPooling3D)      (None, 16, 64, 64, 16)    0         \n",
            "_________________________________________________________________\n",
            "Conv_2 (ConvLSTM2D)          (None, 16, 64, 64, 32)    153728    \n",
            "_________________________________________________________________\n",
            "Batch_2 (BatchNormalization) (None, 16, 64, 64, 32)    128       \n",
            "_________________________________________________________________\n",
            "3dPool_2 (MaxPooling3D)      (None, 8, 32, 32, 32)     0         \n",
            "_________________________________________________________________\n",
            "Conv_3 (ConvLSTM2D)          (None, 8, 32, 32, 64)     614656    \n",
            "_________________________________________________________________\n",
            "Batch_3 (BatchNormalization) (None, 8, 32, 32, 64)     256       \n",
            "_________________________________________________________________\n",
            "3dPool_3 (MaxPooling3D)      (None, 4, 16, 16, 64)     0         \n",
            "_________________________________________________________________\n",
            "final_conv (ConvLSTM2D)      (None, 16, 16, 64)        819456    \n",
            "_________________________________________________________________\n",
            "final_batch (BatchNormalizat (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "final_pool (MaxPooling2D)    (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                65600     \n",
            "=================================================================\n",
            "Total params: 1,684,608\n",
            "Trainable params: 1,684,256\n",
            "Non-trainable params: 352\n",
            "_________________________________________________________________\n",
            "Epoch 1/28\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ef942cbd03f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m       \u001b[0;34m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[32,128,128,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node rgb128_0fold/Conv_1/while/body/_1/rgb128_0fold/Conv_1/while/Add_3-0-0-TransposeNCHWToNHWC-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_13908]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWKR1W_i5s8S"
      },
      "source": [
        "CROSS SAMPLE LENGTH TESTING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWAgwE6MgtZ2"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications import mobilenet\n",
        "from keras.utils import Sequence\n",
        "import math \n",
        "class SequenceGenerator(Sequence):\n",
        "  def __init__(self, videos_path, samples,batch_size, width, height, channels):\n",
        "    self.batch_size = batch_size\n",
        "    self.videos_path = videos_path\n",
        "    self.samples = samples\n",
        "    self.width = width\n",
        "    self.height = height\n",
        "    self.channels = channels\n",
        "    self.len = len(os.listdir(videos_path))\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    batch_samples = self.samples[idx * self.batch_size:(idx+1)*self.batch_size]\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    for batch_sample in batch_samples:      \n",
        "      vidcap = cv2.VideoCapture(os.path.join(self.videos_path,batch_sample))              \n",
        "      frames = []\n",
        "      suc, frame = vidcap.read()              \n",
        "      while suc: \n",
        "        frame = cv2.resize(frame, (self.width,self.height), interpolation=cv2.INTER_AREA)\n",
        "        frame =  cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) if (self.channels==3) else np.expand_dims(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY),2)\n",
        "        frame = frame.astype(np.float32)\n",
        "        frame /= 255.0          \n",
        "        frames.append(frame)\n",
        "        suc, frame = vidcap.read()      \n",
        "      \n",
        "      X_train.append(frames)        \n",
        "      cat = int(batch_sample.split('_')[0])#  Los mp4 estan categorizados de 1 a 64 y los .avi de 0 a 64, asi que no necesito restar 1        \n",
        "      y_train.append(to_categorical(cat, num_classes=64))      \n",
        "        \n",
        "    X_train = np.asarray(X_train, dtype=np.float32)      \n",
        "    y_train = np.asarray(y_train)      \n",
        "    return X_train, y_train\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmrH8i1a2Yzl"
      },
      "source": [
        "import os\n",
        "basePath = \"/content/gdrive/My Drive/Informática/Tesina/\"\n",
        "baseFolder = basePath+'Experimentos/ConvLSTM/Multisampling8/'\n",
        "videos_path = basePath+'Videos/Multisampling8'\n",
        "fls = os.listdir(videos_path)\n",
        "videos_path = basePath+'Videos/Multisampling16'\n",
        "fls = os.listdir(videos_path)\n",
        "videos_path = basePath+'Videos/Multisampling32'\n",
        "fls = os.listdir(videos_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StArHiMYDIg9"
      },
      "source": [
        "DATASET = 'SimpleSampling32'\n",
        "import numpy as np\n",
        "import pickle\n",
        "import functools as ft\n",
        "from keras import Model\n",
        "from keras.optimizers import Adam\n",
        "def addHistories(h1, h2):    \n",
        "    for key in [\"accuracy\", \"loss\", \"val_loss\", \"val_accuracy\"]:\n",
        "        h2[key].append(h1[key]) #ya no es una lista asi que puedo acceder a la metrica directo \n",
        "    return h2\n",
        "\n",
        "basePath = \"/content/gdrive/My Drive/Informática/Tesina/\"\n",
        "baseFolder = basePath+'Experimentos/ConvLSTM/'+DATASET\n",
        "namesPath = basePath+'DatasetsNames/'+DATASET\n",
        "videos_path = basePath+'Videos/'+DATASET\n",
        "best_epochs = {}\n",
        "mean_acc = {'8':[],'16':[], '32':[] }\n",
        "videos_path = {'8':basePath+'Videos/Multisampling8/','16':basePath+'Videos/Multisampling16/', '32':basePath+'Videos/SimpleSampling32/' }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scCbl6-XDC0E",
        "outputId": "7dd052f0-180e-4658-a6dc-826609c402a6"
      },
      "source": [
        "\n",
        "for fold in ['0fold','1fold','2fold', '3fold', '4fold']:\n",
        "  modelName = 'gray'+fold\n",
        "  expFolder = os.path.join(baseFolder,modelName)\n",
        "  if f\"{modelName}.pickle\" in os.listdir(expFolder):  \n",
        "    with open(os.path.join(expFolder, f\"{modelName}.pickle\"), 'rb') as pklfile:\n",
        "      conf = pickle.load(pklfile)    \n",
        "      model = Model.from_config(conf)\n",
        "  else:\n",
        "    print(\"no encuentro modelo\")\n",
        "  adam = Adam(learning_rate=0.001)\n",
        "  model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  EXP_PKL_PATH = os.path.join(expFolder, 'Pickles')  \n",
        "  pkl_files = os.listdir(EXP_PKL_PATH)\n",
        "  fls_s = sorted(pkl_files, key=lambda x: int(x.split('_')[-1].split('.')[0])) #Exp_18_epoch_2.pickle\n",
        "\n",
        "  pkls = []\n",
        "  for pkl_file in fls_s:\n",
        "      with open(os.path.join(EXP_PKL_PATH ,pkl_file), 'rb') as pkl:\n",
        "          h_temp = pickle.load(pkl)        \n",
        "          #print(h_temp)\n",
        "          if 'val_loss' in h_temp.keys():\n",
        "            pkls.append(h_temp)\n",
        "\n",
        "\n",
        "  init_dict = {}\n",
        "  for k in [\"accuracy\", \"loss\", \"val_loss\", \"val_accuracy\"]:\n",
        "    init_dict[k] = []\n",
        "  hs = ft.reduce(lambda a,b: addHistories(b,a), pkls, init_dict)\n",
        "  best_epoch = np.array(hs['val_accuracy']).argmax()+1\n",
        "  best_epochs[fold] = (best_epoch,hs['val_accuracy'][best_epoch-1])\n",
        "  model.load_weights(os.path.join(expFolder,'Weights','{}_epoch_{}.h5'.format(modelName, best_epoch)))\n",
        "  print(hs['val_accuracy'][best_epoch-1])\n",
        "  print(best_epoch)\n",
        "  with open(os.path.join(namesPath,f'test_{fold}_{DATASET}.txt'), 'r') as f:\n",
        "    test = f.read().split('\\n')  \n",
        " \n",
        "  for num_frames in ['32']:\n",
        "    path = videos_path[num_frames]\n",
        "    gen = SequenceGenerator(path, test, 32, 64, 64, 1)    \n",
        "    eval_dict = model.evaluate(\n",
        "          gen\n",
        "        , steps=int(len(test)/32)\n",
        "        , batch_size=32\n",
        "        , verbose = 1\n",
        "        , return_dict=True\n",
        "        ,use_multiprocessing=True\n",
        "        ,workers=4\n",
        "      )\n",
        "    mean_acc[num_frames].append(eval_dict['accuracy'])\n",
        "    with open(os.path.join(expFolder, f'evaluation_epoch{best_epoch}_{num_frames}frames.pickle'), 'wb') as pkl:\n",
        "      pickle.dump(eval_dict, pkl)    \n",
        "  \n",
        "with open(os.path.join(baseFolder, f'graytests.pickle'), 'wb') as pkl:\n",
        "      pickle.dump(mean_acc, pkl)\n",
        "\n",
        "with open(os.path.join(baseFolder, f'graybestEpochs.pickle'), 'wb') as pkl:\n",
        "      pickle.dump(best_epochs, pkl)        \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9709821343421936\n",
            "37\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "20/20 [==============================] - 230s 10s/step - loss: 0.1868 - accuracy: 0.9362\n",
            "0.96875\n",
            "17\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "20/20 [==============================] - 225s 9s/step - loss: 0.0916 - accuracy: 0.9715\n",
            "0.9598214030265808\n",
            "25\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "20/20 [==============================] - 224s 9s/step - loss: 0.1241 - accuracy: 0.9495\n",
            "0.9553571343421936\n",
            "12\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "20/20 [==============================] - 228s 10s/step - loss: 0.2056 - accuracy: 0.9391\n",
            "0.9732142686843872\n",
            "37\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "20/20 [==============================] - 228s 10s/step - loss: 0.1283 - accuracy: 0.9487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W8B4g1L84rn"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}